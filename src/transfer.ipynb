{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Problems:\n",
    "* Decimal is unsupported -> conversion to float\n",
    "* No constraints besides the unique constraints -> all checks should be performed on backend"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase, DirectDriver\n",
    "from neo4j.exceptions import ClientError\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "from time import time\n",
    "from typing import List, Tuple, Optional\n",
    "from decimal import Decimal"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "NEO_LOGIN = \"neo4j\"\n",
    "NEO_PASSWORD = \"bitnami\"\n",
    "\n",
    "uri = \"bolt://localhost:7687\"\n",
    "driver = GraphDatabase.driver(uri, auth=(NEO_LOGIN, NEO_PASSWORD))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "PG_LOGIN = \"DMD2user\"\n",
    "PG_PASS = \"DMD2pgPass\"\n",
    "PG_DB = \"dvdrental\"\n",
    "\n",
    "conn = psycopg2.connect(database=PG_DB, user=PG_LOGIN,\n",
    "                       password=PG_PASS, host=\"localhost\", port=\"5432\")\n",
    "\n",
    "cursor = conn.cursor()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "steps = 42\n",
    "current_step = 1\n",
    "\n",
    "def report():\n",
    "    global steps, current_step\n",
    "    print(f\"{current_step}/{steps} done\")\n",
    "    current_step += 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def proper_type(column_name:str, column_type:str) -> str:\n",
    "    if column_type in [\"integer\", \"int\", \"smallint\", \"bigint\"]:\n",
    "        return f\"toInteger(row.{column_name})\"\n",
    "    elif column_type in [\"numeric\", \"float\", \"decimal\"]:\n",
    "        return f\"toFloat(row.{column_name})\"\n",
    "    elif column_type in [\"boolean\"]:\n",
    "        return f\"toBoolean(row.{column_name})\"\n",
    "    elif column_type in [\"date\"]:\n",
    "        return f'apoc.date.parse(row.{column_name}, \\'s\\', \"yyyy-MM-dd\")'\n",
    "    elif column_type.startswith(\"timestamp\"):\n",
    "        return f\"apoc.date.parse(row.{column_name})\"\n",
    "    else:\n",
    "        return f\"row.{column_name}\"\n",
    "\n",
    "def print_unique_constraint(table:str) ->str:\n",
    "    return f\"CREATE CONSTRAINT ON ({table}:{table.capitalize()}) ASSERT {table}.{table}_id IS UNIQUE\"\n",
    "\n",
    "def print_transfer(table_name:str, with_index=True) -> Tuple[str, str]:\n",
    "    export = f\"copy {table_name} to '/tmp/{table_name}.csv' DELIMITER ',' CSV HEADER;\"\n",
    "    cursor.execute(export)\n",
    "    import_statement = \"USING PERIODIC COMMIT\\n\" \\\n",
    "                       f\"LOAD CSV WITH HEADERS FROM 'file:/{table_name}.csv' AS row\\n\" \\\n",
    "                       f\"MERGE ({table_name.lower()}: {table_name.capitalize()} {{{table_name.lower()}_id:toInteger(row.{table_name.lower()}_id)}})\\n\" \\\n",
    "                       \"\\tON CREATE SET\\n\"\n",
    "\n",
    "    cursor.execute(\"select column_name, data_type from INFORMATION_SCHEMA.COLUMNS where table_name = %s ;\", (table_name,))\n",
    "    \n",
    "    props = []\n",
    "    for column in cursor.fetchall():\n",
    "        column_name, column_type = column\n",
    "        if column_name.endswith(\"_id\"):\n",
    "            continue\n",
    "        props.append(f\"{table_name}.{column_name} = {proper_type(column_name, column_type)}\")\n",
    "    \n",
    "    return print_unique_constraint(table_name), import_statement + \"\\t\\t{data};\".format(data=\",\\n\\t\\t\".join(props))\n",
    "\n",
    "def many2many(table_name:str, from_table:str, to_table:str, rel_name:str) -> str:\n",
    "    export = f\"copy {table_name} to '/tmp/{table_name}.csv' DELIMITER ',' CSV HEADER;\"\n",
    "    cursor.execute(export)\n",
    "    cursor.execute(\"select column_name, data_type from INFORMATION_SCHEMA.COLUMNS where table_name = %s ;\", (table_name,))\n",
    "    \n",
    "    props = []\n",
    "    for column in cursor.fetchall():\n",
    "        column_name, column_type = column\n",
    "        if column_name.endswith(\"_id\"):\n",
    "            continue\n",
    "        props.append(f\"{column_name}: {proper_type(column_name, column_type)}\")\n",
    "        \n",
    "    import_statement = \"USING PERIODIC COMMIT\\n\" \\\n",
    "                       f\"LOAD CSV WITH HEADERS FROM 'file:/{table_name}.csv' AS row\\n\" \\\n",
    "                       f\"MATCH ( {from_table} :{from_table.capitalize()} {{ {from_table}_id: {proper_type(f'{from_table}_id', 'int')} }})\\n\" \\\n",
    "                       f\"MATCH ( {to_table}   :{to_table.capitalize()} {{ {to_table}_id: {proper_type(f'{to_table}_id', 'int')} }})\\n\" \\\n",
    "                       f\"MERGE ( {from_table}) - [:{rel_name.upper()}{{ {','.join(props)} }}] -> ({to_table});\"\n",
    "    return import_statement\n",
    "            \n",
    "def transfer_relation(table_name:str, to_table:str, rel_name:str, \n",
    "                      last_update_to_rel: bool = True, fk:Optional[str] = None) -> str:\n",
    "    if fk is None:\n",
    "        fk = f\"{to_table}_id\"\n",
    "    export = f\"copy (select {table_name}_id, {fk} as {to_table}_id \" \\\n",
    "             f\"{', last_update' if last_update_to_rel else ''}\" \\\n",
    "             f\" from {table_name}) to '/tmp/{table_name}_{to_table}_rel.csv' DELIMITER ',' CSV HEADER;\"\n",
    "    cursor.execute(export)\n",
    "    \n",
    "    props = []\n",
    "    if last_update_to_rel:\n",
    "        props.append(f\"last_update: {proper_type('last_update', 'timestamp')}\")\n",
    "    \n",
    "    import_statement = \"USING PERIODIC COMMIT\\n\" \\\n",
    "                       f\"LOAD CSV WITH HEADERS FROM 'file:/{table_name}_{to_table}_rel.csv' AS row\\n\" \\\n",
    "                       f\"MATCH ( {table_name} :{table_name.capitalize()} {{ {table_name}_id: {proper_type(f'{table_name}_id', 'int')} }})\\n\" \\\n",
    "                       f\"MATCH ( {to_table}   :{to_table.capitalize()} {{ {to_table}_id: {proper_type(f'{to_table}_id', 'int')} }})\\n\" \\\n",
    "                       f\"MERGE ( {table_name}) - [:{rel_name.upper()}{{ {','.join(props)} }}] -> ({to_table});\"\n",
    "    # print(import_statement)\n",
    "    # with driver.session() as session:\n",
    "    #     session.run(import_statement)\n",
    "\n",
    "    return import_statement\n",
    "\n",
    "\n",
    "def execute_statements(statements: List[str]) -> None:\n",
    "    with driver.session() as session:\n",
    "        for statement in statements:\n",
    "            if statement is None:\n",
    "                continue\n",
    "            try:\n",
    "                session.run(statement)\n",
    "                report()\n",
    "            except ClientError:\n",
    "                pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1/29 done\n",
      "2/29 done\n",
      "3/29 done\n",
      "4/29 done\n",
      "5/29 done\n",
      "6/29 done\n",
      "7/29 done\n",
      "8/29 done\n",
      "9/29 done\n",
      "10/29 done\n",
      "11/29 done\n",
      "12/29 done\n",
      "13/29 done\n",
      "14/29 done\n",
      "15/29 done\n",
      "16/29 done\n",
      "17/29 done\n",
      "18/29 done\n",
      "19/29 done\n",
      "20/29 done\n",
      "21/29 done\n",
      "22/29 done\n",
      "23/29 done\n",
      "24/29 done\n",
      "25/29 done\n",
      "26/29 done\n",
      "27/29 done\n",
      "28/29 done\n",
      "29/29 done\n",
      "30/29 done\n",
      "31/29 done\n",
      "32/29 done\n",
      "33/29 done\n",
      "34/29 done\n",
      "35/29 done\n",
      "36/29 done\n",
      "37/29 done\n",
      "38/29 done\n",
      "39/29 done\n",
      "40/29 done\n",
      "41/29 done\n",
      "42/29 done\n",
      "25.667786359786987\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "statements = []\n",
    "\n",
    "tables = [\"category\", \"film\", \"language\", \"actor\", \"staff\",\n",
    "          \"payment\", \"rental\", \"inventory\",\n",
    "          \"customer\", \"address\", \"city\", \"country\", \"store\"]\n",
    "\n",
    "for table in tables:\n",
    "    statements.extend(print_transfer(table))\n",
    "    \n",
    "statements.extend([\n",
    "    many2many(\"film_category\", \"film\", \"category\", \"IN_CATEGORY\"),\n",
    "    many2many(\"film_actor\", \"actor\", \"film\", \"FILMED_IN\"),\n",
    "    transfer_relation(\"film\", \"language\", \"IN_LANGUAGE\"),\n",
    "    transfer_relation(\"inventory\", \"film\", \"RENTS_FILM\"),\n",
    "    transfer_relation(\"rental\", \"inventory\", \"RENTS\"),\n",
    "    transfer_relation(\"rental\", \"customer\", \"RENTED_TO\"),\n",
    "    transfer_relation(\"rental\", \"staff\", \"RENTED_BY\"),\n",
    "    transfer_relation(\"payment\", \"rental\", \"PAID_FOR\", last_update_to_rel=False),\n",
    "    transfer_relation(\"payment\", \"customer\", \"PAID_BY\", last_update_to_rel=False),\n",
    "    transfer_relation(\"payment\", \"staff\", \"ACCEPTED_BY\", last_update_to_rel=False),\n",
    "    transfer_relation(\"customer\", \"address\", \"LIVES_AT\"),\n",
    "    transfer_relation(\"staff\", \"address\", \"LIVES_AT\"),\n",
    "    transfer_relation(\"store\", \"address\", \"LOCATED_AT\"),\n",
    "    transfer_relation(\"address\", \"city\", \"SITUATED_IN\"),\n",
    "    transfer_relation(\"city\", \"country\", \"SITUATED_IN\"),\n",
    "    transfer_relation(\"store\", \"staff\", \"MANAGED_BY\", fk=\"manager_staff_id\"),\n",
    "])\n",
    "\n",
    "execute_statements(statements)\n",
    "\n",
    "print(f\"Time elapsed: {time()-start} seconds\")\n",
    "\n",
    "driver.close()\n",
    "conn.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}